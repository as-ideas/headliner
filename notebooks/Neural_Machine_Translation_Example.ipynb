{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Machine Translation Example",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4vi8tH5xO_x",
        "colab_type": "text"
      },
      "source": [
        "# Neural Machine Translation Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiQIr4FSloBt",
        "colab_type": "code",
        "outputId": "81ec464f-8116-4d5e-8cab-580d7184e57e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        }
      },
      "source": [
        "# Install TensorFlow and also our package via PyPI\n",
        "!pip install tensorflow-gpu==2.0.0\n",
        "!pip install headliner"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/44/47f0722aea081697143fbcf5d2aa60d1aee4aaacb5869aee2b568974777b/tensorflow_gpu-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (380.8MB)\n",
            "\u001b[K     |████████████████████████████████| 380.8MB 68kB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.11.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.1.0)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0 (from tensorflow-gpu==2.0.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/00/5e6cdf86190a70d7382d320b2b04e4ff0f8191a37d90a422a2f8ff0705bb/tensorflow_estimator-2.0.0-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 48.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.16.5)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.8.0)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0 (from tensorflow-gpu==2.0.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/a6/e8ffa4e2ddb216449d34cfcb825ebb38206bee5c4553d69e7bc8bc2c5d64/tensorboard-2.0.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 38.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.33.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.1.7)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (3.7.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.8.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (0.16.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (41.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0) (2.8.0)\n",
            "\u001b[31mERROR: tensorflow 1.15.0rc3 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.15.0rc3 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 2.0.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow-gpu\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "Successfully installed tensorboard-2.0.0 tensorflow-estimator-2.0.0 tensorflow-gpu-2.0.0\n",
            "Collecting headliner\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0b/5d/ce41845d2a93ba2bdff560f895fcb231d76c1cd5c4e152ed0c308d0a0054/headliner-0.0.18-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from headliner) (3.2.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from headliner) (3.13)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from headliner) (0.21.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->headliner) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->headliner) (1.3.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->headliner) (0.14.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->headliner) (1.16.5)\n",
            "Installing collected packages: headliner\n",
            "Successfully installed headliner-0.0.18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLWI5oUvJ1St",
        "colab_type": "code",
        "outputId": "7b6b3ada-03cb-4704-f11a-ba0b2c45c402",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "# Download the German-English sentence pairs\n",
        "!wget http://www.manythings.org/anki/deu-eng.zip\n",
        "!unzip deu-eng.zip\n",
        "!head deu.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-15 15:15:06--  http://www.manythings.org/anki/deu-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 104.24.108.196, 104.24.109.196, 2606:4700:30::6818:6cc4, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|104.24.108.196|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7612057 (7.3M) [application/zip]\n",
            "Saving to: ‘deu-eng.zip’\n",
            "\n",
            "deu-eng.zip         100%[===================>]   7.26M  2.18MB/s    in 3.3s    \n",
            "\n",
            "2019-10-15 15:15:10 (2.18 MB/s) - ‘deu-eng.zip’ saved [7612057/7612057]\n",
            "\n",
            "Archive:  deu-eng.zip\n",
            "  inflating: deu.txt                 \n",
            "  inflating: _about.txt              \n",
            "Hi.\tHallo!\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #380701 (cburgmer)\n",
            "Hi.\tGrüß Gott!\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #659813 (Esperantostern)\n",
            "Run!\tLauf!\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #941078 (Fingerhut)\n",
            "Wow!\tPotzdonner!\tCC-BY 2.0 (France) Attribution: tatoeba.org #52027 (Zifre) & #2122382 (Pfirsichbaeumchen)\n",
            "Wow!\tDonnerwetter!\tCC-BY 2.0 (France) Attribution: tatoeba.org #52027 (Zifre) & #2122391 (Pfirsichbaeumchen)\n",
            "Fire!\tFeuer!\tCC-BY 2.0 (France) Attribution: tatoeba.org #1829639 (Spamster) & #1958697 (Tamy)\n",
            "Help!\tHilfe!\tCC-BY 2.0 (France) Attribution: tatoeba.org #435084 (lukaszpp) & #575889 (MUIRIEL)\n",
            "Help!\tZu Hülf!\tCC-BY 2.0 (France) Attribution: tatoeba.org #435084 (lukaszpp) & #2122375 (Pfirsichbaeumchen)\n",
            "Stop!\tStopp!\tCC-BY 2.0 (France) Attribution: tatoeba.org #448320 (FeuDRenais) & #626467 (jakov)\n",
            "Wait!\tWarte!\tCC-BY 2.0 (France) Attribution: tatoeba.org #1744314 (belgavox) & #2122378 (Pfirsichbaeumchen)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYyOWzeep2lU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the dataset but only take a subset for faster training\n",
        "import io\n",
        "\n",
        "def create_dataset(path, num_examples):\n",
        "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "    word_pairs = [[w for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "    return zip(*word_pairs)\n",
        "\n",
        "test = create_dataset('deu.txt', 30000)\n",
        "\n",
        "eng, ger, _ = create_dataset('deu.txt', 30000)\n",
        "data = list(zip(eng, ger))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPiBB8TCzCVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the dataset into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(data, test_size=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOz2fIXQz_Kz",
        "colab_type": "code",
        "outputId": "b3a1f544-5315-464b-b76b-2bd3f4603be3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Define the model and train it\n",
        "from headliner.trainer import Trainer\n",
        "from headliner.model.summarizer_attention import SummarizerAttention\n",
        "\n",
        "summarizer = SummarizerAttention(lstm_size=1024, embedding_size=256)\n",
        "trainer = Trainer(batch_size=64, \n",
        "                  steps_per_epoch=100, \n",
        "                  steps_to_log=20, \n",
        "                  max_output_len=10, \n",
        "                  model_save_path='/tmp/summarizer')\n",
        "trainer.train(summarizer, train, num_epochs=10, val_data=test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training a bare model, preprocessing data to init model...\n",
            "fitting tokenizers...\n",
            "vocab encoder: 4710, vocab decoder: 7528\n",
            "epoch 0, batch 20, logs: {'loss': 4.143562316894531}\n",
            "epoch 0, batch 40, logs: {'loss': 3.6472667694091796}\n",
            "epoch 0, batch 60, logs: {'loss': 3.3786936442057294}\n",
            "epoch 0, batch 80, logs: {'loss': 3.2139678955078126}\n",
            "epoch 0, batch 100, logs: {'loss': 3.086736755371094}\n",
            "\n",
            "(input) Thank you for this. \n",
            "(target) Danke dafür. \n",
            "(prediction) du ist ist nicht . <end>\n",
            "\n",
            "\n",
            "(input) Do you live there? \n",
            "(target) Lebst du dort? \n",
            "(prediction) du ist ist ? <end>\n",
            "\n",
            "\n",
            "(input) Nobody told me. \n",
            "(target) Das hat mir keiner gesagt. \n",
            "(prediction) ich habe ist nicht . <end>\n",
            "\n",
            "\n",
            "(input) Is Tom bluffing? \n",
            "(target) Blufft Tom? \n",
            "(prediction) tom ist ist ? <end>\n",
            "\n",
            "\n",
            "(input) You're worried. \n",
            "(target) Sie sind besorgt. \n",
            "(prediction) sie ist ist nicht . <end>\n",
            "\n",
            "loss_val improved from None to 2.327824115753174, saving summarizer to /tmp/summarizer\n",
            "epoch 1, batch 120, logs: {'loss': 2.4753684997558594, 'loss_val': 2.327824115753174}\n",
            "epoch 1, batch 140, logs: {'loss': 2.4255605697631837, 'loss_val': 2.327824115753174}\n",
            "epoch 1, batch 160, logs: {'loss': 2.4051287333170572, 'loss_val': 2.327824115753174}\n",
            "epoch 1, batch 180, logs: {'loss': 2.369765281677246, 'loss_val': 2.327824115753174}\n",
            "epoch 1, batch 200, logs: {'loss': 2.343877716064453, 'loss_val': 2.327824115753174}\n",
            "\n",
            "(input) Thank you for this. \n",
            "(target) Danke dafür. \n",
            "(prediction) sie sie sie es nicht . <end>\n",
            "\n",
            "\n",
            "(input) Do you live there? \n",
            "(target) Lebst du dort? \n",
            "(prediction) was was sie sie ? <end>\n",
            "\n",
            "\n",
            "(input) Nobody told me. \n",
            "(target) Das hat mir keiner gesagt. \n",
            "(prediction) ich habe es nicht . <end>\n",
            "\n",
            "\n",
            "(input) Is Tom bluffing? \n",
            "(target) Blufft Tom? \n",
            "(prediction) was ist tom ? <end>\n",
            "\n",
            "\n",
            "(input) You're worried. \n",
            "(target) Sie sind besorgt. \n",
            "(prediction) sie sie sie nicht . <end>\n",
            "\n",
            "loss_val improved from 2.327824115753174 to 1.9956796169281006, saving summarizer to /tmp/summarizer\n",
            "epoch 2, batch 220, logs: {'loss': 2.2164867401123045, 'loss_val': 1.9956796169281006}\n",
            "epoch 2, batch 240, logs: {'loss': 2.1902523040771484, 'loss_val': 1.9956796169281006}\n",
            "epoch 2, batch 260, logs: {'loss': 2.166184488932292, 'loss_val': 1.9956796169281006}\n",
            "epoch 2, batch 280, logs: {'loss': 2.156383514404297, 'loss_val': 1.9956796169281006}\n",
            "epoch 2, batch 300, logs: {'loss': 2.130956726074219, 'loss_val': 1.9956796169281006}\n",
            "\n",
            "(input) Thank you for this. \n",
            "(target) Danke dafür. \n",
            "(prediction) du hast , tom nicht . <end>\n",
            "\n",
            "\n",
            "(input) Do you live there? \n",
            "(target) Lebst du dort? \n",
            "(prediction) hast sie das ? <end>\n",
            "\n",
            "\n",
            "(input) Nobody told me. \n",
            "(target) Das hat mir keiner gesagt. \n",
            "(prediction) ich mag mich . <end>\n",
            "\n",
            "\n",
            "(input) Is Tom bluffing? \n",
            "(target) Blufft Tom? \n",
            "(prediction) wie hat tom tom ? <end>\n",
            "\n",
            "\n",
            "(input) You're worried. \n",
            "(target) Sie sind besorgt. \n",
            "(prediction) du bist ein großer . <end>\n",
            "\n",
            "loss_val improved from 1.9956796169281006 to 1.885825514793396, saving summarizer to /tmp/summarizer\n",
            "epoch 3, batch 320, logs: {'loss': 2.0432205200195312, 'loss_val': 1.885825514793396}\n",
            "epoch 3, batch 340, logs: {'loss': 2.014055633544922, 'loss_val': 1.885825514793396}\n",
            "epoch 3, batch 360, logs: {'loss': 1.997589365641276, 'loss_val': 1.885825514793396}\n",
            "epoch 3, batch 380, logs: {'loss': 1.9854471206665039, 'loss_val': 1.885825514793396}\n",
            "epoch 3, batch 400, logs: {'loss': 1.963772735595703, 'loss_val': 1.885825514793396}\n",
            "\n",
            "(input) Thank you for this. \n",
            "(target) Danke dafür. \n",
            "(prediction) du hast das für , was was haben ich . <end>\n",
            "\n",
            "\n",
            "(input) Do you live there? \n",
            "(target) Lebst du dort? \n",
            "(prediction) sind sie das ? <end>\n",
            "\n",
            "\n",
            "(input) Nobody told me. \n",
            "(target) Das hat mir keiner gesagt. \n",
            "(prediction) gib tom mich nicht . <end>\n",
            "\n",
            "\n",
            "(input) Is Tom bluffing? \n",
            "(target) Blufft Tom? \n",
            "(prediction) ist tom ? <end>\n",
            "\n",
            "\n",
            "(input) You're worried. \n",
            "(target) Sie sind besorgt. \n",
            "(prediction) du hast sie eine beste . <end>\n",
            "\n",
            "loss_val improved from 1.885825514793396 to 1.7362192869186401, saving summarizer to /tmp/summarizer\n",
            "epoch 4, batch 420, logs: {'loss': 1.835274887084961, 'loss_val': 1.7362192869186401}\n",
            "epoch 4, batch 440, logs: {'loss': 1.8114988327026367, 'loss_val': 1.7362192869186401}\n",
            "epoch 4, batch 460, logs: {'loss': 1.8058284759521483, 'loss_val': 1.7362192869186401}\n",
            "finished iterating over dataset, total batches: 467\n",
            "epoch 4, batch 480, logs: {'loss': 1.7836347579956056, 'loss_val': 1.7362192869186401}\n",
            "epoch 4, batch 500, logs: {'loss': 1.738201904296875, 'loss_val': 1.7362192869186401}\n",
            "\n",
            "(input) Thank you for this. \n",
            "(target) Danke dafür. \n",
            "(prediction) was , was du für mir . <end>\n",
            "\n",
            "\n",
            "(input) Do you live there? \n",
            "(target) Lebst du dort? \n",
            "(prediction) hast du das auto ? <end>\n",
            "\n",
            "\n",
            "(input) Nobody told me. \n",
            "(target) Das hat mir keiner gesagt. \n",
            "(prediction) er hat mich mir aufhalten . <end>\n",
            "\n",
            "\n",
            "(input) Is Tom bluffing? \n",
            "(target) Blufft Tom? \n",
            "(prediction) ist tom ? <end>\n",
            "\n",
            "\n",
            "(input) You're worried. \n",
            "(target) Sie sind besorgt. \n",
            "(prediction) du bist deine lügner . <end>\n",
            "\n",
            "loss_val improved from 1.7362192869186401 to 1.6471972465515137, saving summarizer to /tmp/summarizer\n",
            "epoch 5, batch 520, logs: {'loss': 1.5927845001220704, 'loss_val': 1.6471972465515137}\n",
            "epoch 5, batch 540, logs: {'loss': 1.5774782180786133, 'loss_val': 1.6471972465515137}\n",
            "epoch 5, batch 560, logs: {'loss': 1.5508548736572265, 'loss_val': 1.6471972465515137}\n",
            "epoch 5, batch 580, logs: {'loss': 1.5460935592651368, 'loss_val': 1.6471972465515137}\n",
            "epoch 5, batch 600, logs: {'loss': 1.5389073181152344, 'loss_val': 1.6471972465515137}\n",
            "\n",
            "(input) Thank you for this. \n",
            "(target) Danke dafür. \n",
            "(prediction) du siehst , was du bist . <end>\n",
            "\n",
            "\n",
            "(input) Do you live there? \n",
            "(target) Lebst du dort? \n",
            "(prediction) wann kommt sie ? <end>\n",
            "\n",
            "\n",
            "(input) Nobody told me. \n",
            "(target) Das hat mir keiner gesagt. \n",
            "(prediction) er hat mir mir gesagt . <end>\n",
            "\n",
            "\n",
            "(input) Is Tom bluffing? \n",
            "(target) Blufft Tom? \n",
            "(prediction) ist tom ? <end>\n",
            "\n",
            "\n",
            "(input) You're worried. \n",
            "(target) Sie sind besorgt. \n",
            "(prediction) du bist du bist . <end>\n",
            "\n",
            "loss_val improved from 1.6471972465515137 to 1.444100260734558, saving summarizer to /tmp/summarizer\n",
            "epoch 6, batch 620, logs: {'loss': 1.5010078430175782, 'loss_val': 1.444100260734558}\n",
            "epoch 6, batch 640, logs: {'loss': 1.4775970458984375, 'loss_val': 1.444100260734558}\n",
            "epoch 6, batch 660, logs: {'loss': 1.4614873250325522, 'loss_val': 1.444100260734558}\n",
            "epoch 6, batch 680, logs: {'loss': 1.4522440910339356, 'loss_val': 1.444100260734558}\n",
            "epoch 6, batch 700, logs: {'loss': 1.4416806030273437, 'loss_val': 1.444100260734558}\n",
            "\n",
            "(input) Thank you for this. \n",
            "(target) Danke dafür. \n",
            "(prediction) du wünsche dir das für dir . <end>\n",
            "\n",
            "\n",
            "(input) Do you live there? \n",
            "(target) Lebst du dort? \n",
            "(prediction) geht es hier ? <end>\n",
            "\n",
            "\n",
            "(input) Nobody told me. \n",
            "(target) Das hat mir keiner gesagt. \n",
            "(prediction) niemand hat mir mir . <end>\n",
            "\n",
            "\n",
            "(input) Is Tom bluffing? \n",
            "(target) Blufft Tom? \n",
            "(prediction) ist tom ? <end>\n",
            "\n",
            "\n",
            "(input) You're worried. \n",
            "(target) Sie sind besorgt. \n",
            "(prediction) du bist , was du willst . <end>\n",
            "\n",
            "loss_val improved from 1.444100260734558 to 1.308484673500061, saving summarizer to /tmp/summarizer\n",
            "epoch 7, batch 720, logs: {'loss': 1.3688529014587403, 'loss_val': 1.308484673500061}\n",
            "epoch 7, batch 740, logs: {'loss': 1.3617330551147462, 'loss_val': 1.308484673500061}\n",
            "epoch 7, batch 760, logs: {'loss': 1.3525126139322916, 'loss_val': 1.308484673500061}\n",
            "epoch 7, batch 780, logs: {'loss': 1.3431960105895997, 'loss_val': 1.308484673500061}\n",
            "epoch 7, batch 800, logs: {'loss': 1.3394017028808594, 'loss_val': 1.308484673500061}\n",
            "\n",
            "(input) Thank you for this. \n",
            "(target) Danke dafür. \n",
            "(prediction) du wirst das für dir gefallen . <end>\n",
            "\n",
            "\n",
            "(input) Do you live there? \n",
            "(target) Lebst du dort? \n",
            "(prediction) sind sie da ? <end>\n",
            "\n",
            "\n",
            "(input) Nobody told me. \n",
            "(target) Das hat mir keiner gesagt. \n",
            "(prediction) keiner hat es mir gesagt . <end>\n",
            "\n",
            "\n",
            "(input) Is Tom bluffing? \n",
            "(target) Blufft Tom? \n",
            "(prediction) ist tom in der ruhestand ? <end>\n",
            "\n",
            "\n",
            "(input) You're worried. \n",
            "(target) Sie sind besorgt. \n",
            "(prediction) du bist dir für den ruhestand . <end>\n",
            "\n",
            "loss_val improved from 1.308484673500061 to 1.191557765007019, saving summarizer to /tmp/summarizer\n",
            "epoch 8, batch 820, logs: {'loss': 1.2993093490600587, 'loss_val': 1.191557765007019}\n",
            "epoch 8, batch 840, logs: {'loss': 1.2934735298156739, 'loss_val': 1.191557765007019}\n",
            "epoch 8, batch 860, logs: {'loss': 1.2689769744873047, 'loss_val': 1.191557765007019}\n",
            "epoch 8, batch 880, logs: {'loss': 1.267788791656494, 'loss_val': 1.191557765007019}\n",
            "epoch 8, batch 900, logs: {'loss': 1.2592303466796875, 'loss_val': 1.191557765007019}\n",
            "\n",
            "(input) Thank you for this. \n",
            "(target) Danke dafür. \n",
            "(prediction) du machst , dass du das gehört . <end>\n",
            "\n",
            "\n",
            "(input) Do you live there? \n",
            "(target) Lebst du dort? \n",
            "(prediction) bist du da ? <end>\n",
            "\n",
            "\n",
            "(input) Nobody told me. \n",
            "(target) Das hat mir keiner gesagt. \n",
            "(prediction) niemand hat es mir freude . <end>\n",
            "\n",
            "\n",
            "(input) Is Tom bluffing? \n",
            "(target) Blufft Tom? \n",
            "(prediction) ist tom in boston ? <end>\n",
            "\n",
            "\n",
            "(input) You're worried. \n",
            "(target) Sie sind besorgt. \n",
            "(prediction) du hast dir für dich verloren . <end>\n",
            "\n",
            "loss_val improved from 1.191557765007019 to 1.1142483949661255, saving summarizer to /tmp/summarizer\n",
            "epoch 9, batch 920, logs: {'loss': 1.2191353797912599, 'loss_val': 1.1142483949661255}\n",
            "finished iterating over dataset, total batches: 934\n",
            "epoch 9, batch 940, logs: {'loss': 1.1773293495178223, 'loss_val': 1.1142483949661255}\n",
            "epoch 9, batch 960, logs: {'loss': 1.1095858256022135, 'loss_val': 1.1142483949661255}\n",
            "epoch 9, batch 980, logs: {'loss': 1.072535514831543, 'loss_val': 1.1142483949661255}\n",
            "epoch 9, batch 1000, logs: {'loss': 1.045841522216797, 'loss_val': 1.1142483949661255}\n",
            "\n",
            "(input) Thank you for this. \n",
            "(target) Danke dafür. \n",
            "(prediction) hallo , du hast das gehört . <end>\n",
            "\n",
            "\n",
            "(input) Do you live there? \n",
            "(target) Lebst du dort? \n",
            "(prediction) wohnt du da ? <end>\n",
            "\n",
            "\n",
            "(input) Nobody told me. \n",
            "(target) Das hat mir keiner gesagt. \n",
            "(prediction) niemand hat es mir versucht . <end>\n",
            "\n",
            "\n",
            "(input) Is Tom bluffing? \n",
            "(target) Blufft Tom? \n",
            "(prediction) ist tom in der verantwortung ? <end>\n",
            "\n",
            "\n",
            "(input) You're worried. \n",
            "(target) Sie sind besorgt. \n",
            "(prediction) du hast dir fehlen . <end>\n",
            "\n",
            "loss_val improved from 1.1142483949661255 to 1.0403274297714233, saving summarizer to /tmp/summarizer\n",
            "finished iterating over dataset, total batches: 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKYgDLngooL1",
        "colab_type": "code",
        "outputId": "72a63658-297e-4445-f850-505d3807dc83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Do some prediction\n",
        "summarizer.predict('How are you?')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'wie geht es dir ? <end>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    }
  ]
}