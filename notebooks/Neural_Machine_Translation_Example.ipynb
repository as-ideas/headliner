{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Machine Translation Example",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4vi8tH5xO_x",
        "colab_type": "text"
      },
      "source": [
        "# Neural Machine Translation Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiQIr4FSloBt",
        "colab_type": "code",
        "outputId": "6cb90079-9477-4b86-af47-4bb289b52d27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Install the package via PyPI\n",
        "!pip install headliner"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting headliner\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/4b/9d97ce8ac3738b669c40143e2a32424a6c18d4e488856e78a8c8d9518ed9/headliner-0.0.5-py3-none-any.whl\n",
            "Collecting nltk==3.4.5 (from headliner)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 7.7MB/s \n",
            "\u001b[?25hCollecting pyyaml==5.1.2 (from headliner)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/e8/b3212641ee2718d556df0f23f78de8303f068fe29cdaa7a91018849582fe/PyYAML-5.1.2.tar.gz (265kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 37.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn==0.21.3 in /usr/local/lib/python3.6/dist-packages (from headliner) (0.21.3)\n",
            "Collecting tensorflow==2.0.0 (from headliner)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/0f/7bd55361168bb32796b360ad15a25de6966c9c1beb58a8e30c01c8279862/tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk==3.4.5->headliner) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21.3->headliner) (1.16.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21.3->headliner) (1.3.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21.3->headliner) (0.13.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0->headliner) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0->headliner) (0.8.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0->headliner) (1.11.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0->headliner) (3.7.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0->headliner) (0.33.6)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0->headliner) (1.0.8)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0->headliner) (0.1.7)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0 (from tensorflow==2.0.0->headliner)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/a6/e8ffa4e2ddb216449d34cfcb825ebb38206bee5c4553d69e7bc8bc2c5d64/tensorboard-2.0.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 27.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0->headliner) (3.0.1)\n",
            "Collecting gast==0.2.2 (from tensorflow==2.0.0->headliner)\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0->headliner) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0->headliner) (0.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0->headliner) (1.1.0)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0 (from tensorflow==2.0.0->headliner)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/00/5e6cdf86190a70d7382d320b2b04e4ff0f8191a37d90a422a2f8ff0705bb/tensorflow_estimator-2.0.0-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 35.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0->headliner) (41.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0->headliner) (2.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->headliner) (0.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->headliner) (3.1.1)\n",
            "Building wheels for collected packages: nltk, pyyaml, gast\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-cp36-none-any.whl size=1449906 sha256=34d26861b3c473168e648393b0e53b671532ba37a9fd360448f5d981a4bfb3cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.1.2-cp36-cp36m-linux_x86_64.whl size=44104 sha256=a293791976da2a26e06e4f1c54ba9e66d58b0ee198d92b0dcc5b92df741cfc2f\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/45/dd/65f0b38450c47cf7e5312883deb97d065e030c5cca0a365030\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=fa4113ac17731648ba5d079ea2e5e620a4901af24b087cd9b3ce5047f6b696b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built nltk pyyaml gast\n",
            "Installing collected packages: nltk, pyyaml, tensorboard, gast, tensorflow-estimator, tensorflow, headliner\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: tensorboard 1.14.0\n",
            "    Uninstalling tensorboard-1.14.0:\n",
            "      Successfully uninstalled tensorboard-1.14.0\n",
            "  Found existing installation: gast 0.3.2\n",
            "    Uninstalling gast-0.3.2:\n",
            "      Successfully uninstalled gast-0.3.2\n",
            "  Found existing installation: tensorflow-estimator 1.14.0\n",
            "    Uninstalling tensorflow-estimator-1.14.0:\n",
            "      Successfully uninstalled tensorflow-estimator-1.14.0\n",
            "  Found existing installation: tensorflow 1.14.0\n",
            "    Uninstalling tensorflow-1.14.0:\n",
            "      Successfully uninstalled tensorflow-1.14.0\n",
            "Successfully installed gast-0.2.2 headliner-0.0.5 nltk-3.4.5 pyyaml-5.1.2 tensorboard-2.0.0 tensorflow-2.0.0 tensorflow-estimator-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLWI5oUvJ1St",
        "colab_type": "code",
        "outputId": "8fd0a651-712d-4b33-ebe9-cfe40ec1cab4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "# Download the German-English sentence pairs\n",
        "!wget http://www.manythings.org/anki/deu-eng.zip\n",
        "!unzip deu-eng.zip\n",
        "!head deu.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-01 14:57:17--  http://www.manythings.org/anki/deu-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 104.24.108.196, 104.24.109.196, 2606:4700:30::6818:6dc4, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|104.24.108.196|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4541707 (4.3M) [application/zip]\n",
            "Saving to: ‘deu-eng.zip’\n",
            "\n",
            "deu-eng.zip         100%[===================>]   4.33M  2.44MB/s    in 1.8s    \n",
            "\n",
            "2019-10-01 14:57:19 (2.44 MB/s) - ‘deu-eng.zip’ saved [4541707/4541707]\n",
            "\n",
            "Archive:  deu-eng.zip\n",
            "  inflating: deu.txt                 \n",
            "  inflating: _about.txt              \n",
            "Hi.\tHallo!\n",
            "Hi.\tGrüß Gott!\n",
            "Run!\tLauf!\n",
            "Wow!\tPotzdonner!\n",
            "Wow!\tDonnerwetter!\n",
            "Fire!\tFeuer!\n",
            "Help!\tHilfe!\n",
            "Help!\tZu Hülf!\n",
            "Stop!\tStopp!\n",
            "Wait!\tWarte!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYyOWzeep2lU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the dataset\n",
        "import io\n",
        "\n",
        "def create_dataset(path, num_examples):\n",
        "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "    word_pairs = [[w for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "    return zip(*word_pairs)\n",
        "\n",
        "eng, ger = create_dataset('deu.txt', 500)\n",
        "data = list(zip(ger, eng))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPiBB8TCzCVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the dataset into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(data, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOz2fIXQz_Kz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9f455f71-b059-4123-aaf2-419a8b3262a8"
      },
      "source": [
        "# Define the model and train it\n",
        "from headliner.trainer import Trainer\n",
        "from headliner.model.summarizer_attention import SummarizerAttention\n",
        "\n",
        "summarizer = SummarizerAttention(lstm_size=64, embedding_size=24)\n",
        "trainer = Trainer(batch_size=32, steps_per_epoch=100, steps_to_log=20, model_save_path='/tmp/summarizer')\n",
        "trainer.train(summarizer, train, num_epochs=10, val_data=test)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training a bare model, initializing preprocessing...\n",
            "vocab encoder: 383, vocab decoder: 203, start training loop...\n",
            "finished iterating over dataset, total batches: 14\n",
            "epoch 0, batch 20, logs: {'loss': 4.0605316162109375}\n",
            "finished iterating over dataset, total batches: 28\n",
            "epoch 0, batch 40, logs: {'loss': 3.1279962062835693}\n",
            "finished iterating over dataset, total batches: 42\n",
            "finished iterating over dataset, total batches: 56\n",
            "epoch 0, batch 60, logs: {'loss': 2.5084290504455566}\n",
            "finished iterating over dataset, total batches: 70\n",
            "epoch 0, batch 80, logs: {'loss': 2.934246778488159}\n",
            "finished iterating over dataset, total batches: 84\n",
            "finished iterating over dataset, total batches: 98\n",
            "epoch 0, batch 100, logs: {'loss': 2.871776580810547}\n",
            "\n",
            "(input) Ich bin auf. \n",
            "(target) I'm up. \n",
            "(prediction) . . <end>\n",
            "\n",
            "\n",
            "(input) Ich bin neu. \n",
            "(target) I'm new. \n",
            "(prediction) . . <end>\n",
            "\n",
            "\n",
            "(input) Rettet Tom! \n",
            "(target) Save Tom. \n",
            "(prediction) . . <end>\n",
            "\n",
            "\n",
            "(input) Ich benutze es. \n",
            "(target) I use it. \n",
            "(prediction) . . <end>\n",
            "\n",
            "\n",
            "(input) Ich bin 19. \n",
            "(target) I'm 19. \n",
            "(prediction) . . <end>\n",
            "\n",
            "loss_val improved from None to 2.4804513454437256, saving summarizer to /tmp/summarizer\n",
            "finished iterating over dataset, total batches: 112\n",
            "epoch 1, batch 120, logs: {'loss': 2.827357769012451, 'loss_val': 2.4804513454437256}\n",
            "finished iterating over dataset, total batches: 126\n",
            "epoch 1, batch 140, logs: {'loss': 2.1207051277160645, 'loss_val': 2.4804513454437256}\n",
            "finished iterating over dataset, total batches: 140\n",
            "finished iterating over dataset, total batches: 154\n",
            "epoch 1, batch 160, logs: {'loss': 2.0716757774353027, 'loss_val': 2.4804513454437256}\n",
            "finished iterating over dataset, total batches: 168\n",
            "epoch 1, batch 180, logs: {'loss': 1.9911081790924072, 'loss_val': 2.4804513454437256}\n",
            "finished iterating over dataset, total batches: 182\n",
            "finished iterating over dataset, total batches: 196\n",
            "epoch 1, batch 200, logs: {'loss': 2.013056516647339, 'loss_val': 2.4804513454437256}\n",
            "\n",
            "(input) Ich bin auf. \n",
            "(target) I'm up. \n",
            "(prediction) i tom . <end>\n",
            "\n",
            "\n",
            "(input) Ich bin neu. \n",
            "(target) I'm new. \n",
            "(prediction) i tom . <end>\n",
            "\n",
            "\n",
            "(input) Rettet Tom! \n",
            "(target) Save Tom. \n",
            "(prediction) get . . <end>\n",
            "\n",
            "\n",
            "(input) Ich benutze es. \n",
            "(target) I use it. \n",
            "(prediction) i tom . <end>\n",
            "\n",
            "\n",
            "(input) Ich bin 19. \n",
            "(target) I'm 19. \n",
            "(prediction) i tom . <end>\n",
            "\n",
            "loss_val improved from 2.4804513454437256 to 2.1256721019744873, saving summarizer to /tmp/summarizer\n",
            "finished iterating over dataset, total batches: 210\n",
            "epoch 2, batch 220, logs: {'loss': 1.8631160259246826, 'loss_val': 2.1256721019744873}\n",
            "finished iterating over dataset, total batches: 224\n",
            "finished iterating over dataset, total batches: 238\n",
            "epoch 2, batch 240, logs: {'loss': 1.8965070247650146, 'loss_val': 2.1256721019744873}\n",
            "finished iterating over dataset, total batches: 252\n",
            "epoch 2, batch 260, logs: {'loss': 2.0860862731933594, 'loss_val': 2.1256721019744873}\n",
            "finished iterating over dataset, total batches: 266\n",
            "epoch 2, batch 280, logs: {'loss': 2.1016926765441895, 'loss_val': 2.1256721019744873}\n",
            "finished iterating over dataset, total batches: 280\n",
            "finished iterating over dataset, total batches: 294\n",
            "epoch 2, batch 300, logs: {'loss': 2.0573770999908447, 'loss_val': 2.1256721019744873}\n",
            "\n",
            "(input) Ich bin auf. \n",
            "(target) I'm up. \n",
            "(prediction) i i'm . <end>\n",
            "\n",
            "\n",
            "(input) Ich bin neu. \n",
            "(target) I'm new. \n",
            "(prediction) i i . . <end>\n",
            "\n",
            "\n",
            "(input) Rettet Tom! \n",
            "(target) Save Tom. \n",
            "(prediction) get tom . <end>\n",
            "\n",
            "\n",
            "(input) Ich benutze es. \n",
            "(target) I use it. \n",
            "(prediction) i tom . <end>\n",
            "\n",
            "\n",
            "(input) Ich bin 19. \n",
            "(target) I'm 19. \n",
            "(prediction) i i'm . <end>\n",
            "\n",
            "loss_val improved from 2.1256721019744873 to 1.924546241760254, saving summarizer to /tmp/summarizer\n",
            "finished iterating over dataset, total batches: 308\n",
            "epoch 3, batch 320, logs: {'loss': 1.8682533502578735, 'loss_val': 1.924546241760254}\n",
            "finished iterating over dataset, total batches: 322\n",
            "finished iterating over dataset, total batches: 336\n",
            "epoch 3, batch 340, logs: {'loss': 1.3201712369918823, 'loss_val': 1.924546241760254}\n",
            "finished iterating over dataset, total batches: 350\n",
            "epoch 3, batch 360, logs: {'loss': 1.8509759902954102, 'loss_val': 1.924546241760254}\n",
            "finished iterating over dataset, total batches: 364\n",
            "finished iterating over dataset, total batches: 378\n",
            "epoch 3, batch 380, logs: {'loss': 1.6434879302978516, 'loss_val': 1.924546241760254}\n",
            "finished iterating over dataset, total batches: 392\n",
            "epoch 3, batch 400, logs: {'loss': 1.3531877994537354, 'loss_val': 1.924546241760254}\n",
            "\n",
            "(input) Ich bin auf. \n",
            "(target) I'm up. \n",
            "(prediction) i i'm . <end>\n",
            "\n",
            "\n",
            "(input) Ich bin neu. \n",
            "(target) I'm new. \n",
            "(prediction) i i'm . <end>\n",
            "\n",
            "\n",
            "(input) Rettet Tom! \n",
            "(target) Save Tom. \n",
            "(prediction) tom tom . <end>\n",
            "\n",
            "\n",
            "(input) Ich benutze es. \n",
            "(target) I use it. \n",
            "(prediction) i tom . <end>\n",
            "\n",
            "\n",
            "(input) Ich bin 19. \n",
            "(target) I'm 19. \n",
            "(prediction) i i'm . <end>\n",
            "\n",
            "loss_val improved from 1.924546241760254 to 1.7149600982666016, saving summarizer to /tmp/summarizer\n",
            "finished iterating over dataset, total batches: 406\n",
            "epoch 4, batch 420, logs: {'loss': 1.337044358253479, 'loss_val': 1.7149600982666016}\n",
            "finished iterating over dataset, total batches: 420\n",
            "finished iterating over dataset, total batches: 434\n",
            "epoch 4, batch 440, logs: {'loss': 1.257891058921814, 'loss_val': 1.7149600982666016}\n",
            "finished iterating over dataset, total batches: 448\n",
            "epoch 4, batch 460, logs: {'loss': 1.508056640625, 'loss_val': 1.7149600982666016}\n",
            "finished iterating over dataset, total batches: 462\n",
            "finished iterating over dataset, total batches: 476\n",
            "epoch 4, batch 480, logs: {'loss': 0.959786593914032, 'loss_val': 1.7149600982666016}\n",
            "finished iterating over dataset, total batches: 490\n",
            "epoch 4, batch 500, logs: {'loss': 1.2180509567260742, 'loss_val': 1.7149600982666016}\n",
            "\n",
            "(input) Ich bin auf. \n",
            "(target) I'm up. \n",
            "(prediction) i'm fell . <end>\n",
            "\n",
            "\n",
            "(input) Ich bin neu. \n",
            "(target) I'm new. \n",
            "(prediction) i'm i'm . <end>\n",
            "\n",
            "\n",
            "(input) Rettet Tom! \n",
            "(target) Save Tom. \n",
            "(prediction) tom tom . <end>\n",
            "\n",
            "\n",
            "(input) Ich benutze es. \n",
            "(target) I use it. \n",
            "(prediction) i'm me . <end>\n",
            "\n",
            "\n",
            "(input) Ich bin 19. \n",
            "(target) I'm 19. \n",
            "(prediction) i'm me . <end>\n",
            "\n",
            "loss_val improved from 1.7149600982666016 to 1.572138786315918, saving summarizer to /tmp/summarizer\n",
            "finished iterating over dataset, total batches: 504\n",
            "finished iterating over dataset, total batches: 518\n",
            "epoch 5, batch 520, logs: {'loss': 1.3074191808700562, 'loss_val': 1.572138786315918}\n",
            "finished iterating over dataset, total batches: 532\n",
            "epoch 5, batch 540, logs: {'loss': 1.0271317958831787, 'loss_val': 1.572138786315918}\n",
            "finished iterating over dataset, total batches: 546\n",
            "epoch 5, batch 560, logs: {'loss': 1.3217065334320068, 'loss_val': 1.572138786315918}\n",
            "finished iterating over dataset, total batches: 560\n",
            "finished iterating over dataset, total batches: 574\n",
            "epoch 5, batch 580, logs: {'loss': 1.0955780744552612, 'loss_val': 1.572138786315918}\n",
            "finished iterating over dataset, total batches: 588\n",
            "epoch 5, batch 600, logs: {'loss': 1.0072882175445557, 'loss_val': 1.572138786315918}\n",
            "\n",
            "(input) Ich bin auf. \n",
            "(target) I'm up. \n",
            "(prediction) i got . <end>\n",
            "\n",
            "\n",
            "(input) Ich bin neu. \n",
            "(target) I'm new. \n",
            "(prediction) i'm i'm . <end>\n",
            "\n",
            "\n",
            "(input) Rettet Tom! \n",
            "(target) Save Tom. \n",
            "(prediction) tom tom . <end>\n",
            "\n",
            "\n",
            "(input) Ich benutze es. \n",
            "(target) I use it. \n",
            "(prediction) i fell . <end>\n",
            "\n",
            "\n",
            "(input) Ich bin 19. \n",
            "(target) I'm 19. \n",
            "(prediction) i'm fell . <end>\n",
            "\n",
            "loss_val improved from 1.572138786315918 to 1.5417011976242065, saving summarizer to /tmp/summarizer\n",
            "finished iterating over dataset, total batches: 602\n",
            "finished iterating over dataset, total batches: 616\n",
            "epoch 6, batch 620, logs: {'loss': 1.2228447198867798, 'loss_val': 1.5417011976242065}\n",
            "finished iterating over dataset, total batches: 630\n",
            "epoch 6, batch 640, logs: {'loss': 1.061379075050354, 'loss_val': 1.5417011976242065}\n",
            "finished iterating over dataset, total batches: 644\n",
            "finished iterating over dataset, total batches: 658\n",
            "epoch 6, batch 660, logs: {'loss': 0.9578781127929688, 'loss_val': 1.5417011976242065}\n",
            "finished iterating over dataset, total batches: 672\n",
            "epoch 6, batch 680, logs: {'loss': 1.0495516061782837, 'loss_val': 1.5417011976242065}\n",
            "finished iterating over dataset, total batches: 686\n",
            "epoch 6, batch 700, logs: {'loss': 0.9216777682304382, 'loss_val': 1.5417011976242065}\n",
            "\n",
            "(input) Ich bin auf. \n",
            "(target) I'm up. \n",
            "(prediction) i helped . <end>\n",
            "\n",
            "\n",
            "(input) Ich bin neu. \n",
            "(target) I'm new. \n",
            "(prediction) i'm got . <end>\n",
            "\n",
            "\n",
            "(input) Rettet Tom! \n",
            "(target) Save Tom. \n",
            "(prediction) tom tom . <end>\n",
            "\n",
            "\n",
            "(input) Ich benutze es. \n",
            "(target) I use it. \n",
            "(prediction) i fell . <end>\n",
            "\n",
            "\n",
            "(input) Ich bin 19. \n",
            "(target) I'm 19. \n",
            "(prediction) i'm fell . <end>\n",
            "\n",
            "loss_val improved from 1.5417011976242065 to 1.5331631898880005, saving summarizer to /tmp/summarizer\n",
            "finished iterating over dataset, total batches: 700\n",
            "finished iterating over dataset, total batches: 714\n",
            "epoch 7, batch 720, logs: {'loss': 1.0204342603683472, 'loss_val': 1.5331631898880005}\n",
            "finished iterating over dataset, total batches: 728\n",
            "epoch 7, batch 740, logs: {'loss': 0.8353517651557922, 'loss_val': 1.5331631898880005}\n",
            "finished iterating over dataset, total batches: 742\n",
            "finished iterating over dataset, total batches: 756\n",
            "epoch 7, batch 760, logs: {'loss': 0.733566403388977, 'loss_val': 1.5331631898880005}\n",
            "finished iterating over dataset, total batches: 770\n",
            "epoch 7, batch 780, logs: {'loss': 0.7467740774154663, 'loss_val': 1.5331631898880005}\n",
            "finished iterating over dataset, total batches: 784\n",
            "finished iterating over dataset, total batches: 798\n",
            "epoch 7, batch 800, logs: {'loss': 0.973666787147522, 'loss_val': 1.5331631898880005}\n",
            "\n",
            "(input) Ich bin auf. \n",
            "(target) I'm up. \n",
            "(prediction) i'm got . <end>\n",
            "\n",
            "\n",
            "(input) Ich bin neu. \n",
            "(target) I'm new. \n",
            "(prediction) i'm got . <end>\n",
            "\n",
            "\n",
            "(input) Rettet Tom! \n",
            "(target) Save Tom. \n",
            "(prediction) tom tom . <end>\n",
            "\n",
            "\n",
            "(input) Ich benutze es. \n",
            "(target) I use it. \n",
            "(prediction) i fell . <end>\n",
            "\n",
            "\n",
            "(input) Ich bin 19. \n",
            "(target) I'm 19. \n",
            "(prediction) i'm fell . <end>\n",
            "\n",
            "loss_val did not improve.\n",
            "finished iterating over dataset, total batches: 812\n",
            "epoch 8, batch 820, logs: {'loss': 0.8501043915748596, 'loss_val': 1.5535986423492432}\n",
            "finished iterating over dataset, total batches: 826\n",
            "epoch 8, batch 840, logs: {'loss': 0.8229829668998718, 'loss_val': 1.5535986423492432}\n",
            "finished iterating over dataset, total batches: 840\n",
            "finished iterating over dataset, total batches: 854\n",
            "epoch 8, batch 860, logs: {'loss': 0.7662054300308228, 'loss_val': 1.5535986423492432}\n",
            "finished iterating over dataset, total batches: 868\n",
            "epoch 8, batch 880, logs: {'loss': 0.8745929002761841, 'loss_val': 1.5535986423492432}\n",
            "finished iterating over dataset, total batches: 882\n",
            "finished iterating over dataset, total batches: 896\n",
            "epoch 8, batch 900, logs: {'loss': 0.7420395612716675, 'loss_val': 1.5535986423492432}\n",
            "\n",
            "(input) Ich bin auf. \n",
            "(target) I'm up. \n",
            "(prediction) i game . <end>\n",
            "\n",
            "\n",
            "(input) Ich bin neu. \n",
            "(target) I'm new. \n",
            "(prediction) i'm got it . <end>\n",
            "\n",
            "\n",
            "(input) Rettet Tom! \n",
            "(target) Save Tom. \n",
            "(prediction) call tom . <end>\n",
            "\n",
            "\n",
            "(input) Ich benutze es. \n",
            "(target) I use it. \n",
            "(prediction) i stayed . <end>\n",
            "\n",
            "\n",
            "(input) Ich bin 19. \n",
            "(target) I'm 19. \n",
            "(prediction) i'm game . <end>\n",
            "\n",
            "loss_val did not improve.\n",
            "finished iterating over dataset, total batches: 910\n",
            "epoch 9, batch 920, logs: {'loss': 0.8419446349143982, 'loss_val': 1.5668771266937256}\n",
            "finished iterating over dataset, total batches: 924\n",
            "finished iterating over dataset, total batches: 938\n",
            "epoch 9, batch 940, logs: {'loss': 0.7608303427696228, 'loss_val': 1.5668771266937256}\n",
            "finished iterating over dataset, total batches: 952\n",
            "epoch 9, batch 960, logs: {'loss': 0.74839848279953, 'loss_val': 1.5668771266937256}\n",
            "finished iterating over dataset, total batches: 966\n",
            "epoch 9, batch 980, logs: {'loss': 0.5740910172462463, 'loss_val': 1.5668771266937256}\n",
            "finished iterating over dataset, total batches: 980\n",
            "finished iterating over dataset, total batches: 994\n",
            "epoch 9, batch 1000, logs: {'loss': 0.731425940990448, 'loss_val': 1.5668771266937256}\n",
            "\n",
            "(input) Ich bin auf. \n",
            "(target) I'm up. \n",
            "(prediction) i try . <end>\n",
            "\n",
            "\n",
            "(input) Ich bin neu. \n",
            "(target) I'm new. \n",
            "(prediction) i'm tried . <end>\n",
            "\n",
            "\n",
            "(input) Rettet Tom! \n",
            "(target) Save Tom. \n",
            "(prediction) kiss tom . <end>\n",
            "\n",
            "\n",
            "(input) Ich benutze es. \n",
            "(target) I use it. \n",
            "(prediction) i stayed . <end>\n",
            "\n",
            "\n",
            "(input) Ich bin 19. \n",
            "(target) I'm 19. \n",
            "(prediction) i'm ok . <end>\n",
            "\n",
            "loss_val did not improve.\n",
            "finished iterating over dataset, total batches: 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKYgDLngooL1",
        "colab_type": "code",
        "outputId": "aabaedce-3e4c-46c8-9305-e7d751c37a76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Do some prediction\n",
        "summarizer.predict('Hi.')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'come on . <end>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u62rjlcu1AKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}